<html>
<head>
<title>Python ThreadingX</title>
<style type='text/css'>
body {
   background-color: #f0f0f0;
   font-family: arial;
}
pre {
   background-color: #f0f0f0;
   padding: 20px;
   margin: 10px;
}
.div1 {
   background-color: #c0c0c0;
   margin: 20px;
   padding: 10px;
}
.div2 {
   background-color: white;
   margin: 10px;
   padding: 30px;
}
</style>
</head>
<body>
<div class='div1'>
<div class='div2'>
<h1>Python ThreadingX</h1>

<h2>What is Python ThreadingX?</h2>

<p>Python ThreadingX aims to make it easy to write multi-threaded applications in Python, which can run across multiple cores, and avoid issues with the Global Interpreter Lock ("GIL")</p>

<p>Specifically:</p>
<ul>
<li>Easy to launch a module as a new process</li>
<li>Easy to communicate with the new process using simple function call symantics</li>
<li>Runs in standard Python</li>
<li>In a multi-core environment, each process can run on a different processor core</li>
</ul>

<h2>Benchmarking</h2>

<p>Compared with Python classic threads, threadx threads are 'heavier', use more memory (about 1MB per process), and have a longer setup time (about 100milliseconds) but can make usage of multiple cores, so once they get going they are a lot faster, up to twice the speed on a dual-core for example.</p>

<h3>primes benchmark</h3>

<p>Calculate prime numbers up to 400000 using a basic sieve of Arystophenes.  Do this four times, in four sub-processes.</p>

<p>The benchmark is in the 'examples' directory, under 'primes'

<h4>Results</h4>

<p>Environment: eeepc 901, ubuntu jaunty, Intel Atom (two cores)</p>

<p>Classic python threads:</p>
<pre>
> time python primesclassicthreads.py

real	0m7.110s
user	0m5.828s
sys	0m2.040s
</pre>

<p>ThreadingX:</p>
<pre>
> time python threadxprimes.py 

real	0m3.626s
user	0m6.288s
sys	0m0.288s
</pre>

Whilst the user time is slightly more for threadingx - because of the process setup overhead - the real time is nearly half, because threadingx can take advantage of the two available cores, and is not blocked by python's global interpreter lock.

<h3>md5 benchmark</h3>

<p>Four processes are created, each of which:</p>
<ul>
<li>create a random string of 100,000 letters</li>
<li>return the md5 hexdigest of this string</li>
</ul>

<p>The benchmark is in the 'examples' directory, under 'md5'

<h4>Results</h4>

<p>Environment: eeepc 901, ubuntu jaunty, Intel Atom (two cores)</p>

<p>Classic python threads:</p>
<pre>
> time python md5classicthreads.py 

real	0m8.357s
user	0m7.832s
sys	0m1.268s
</pre>

<p>ThreadingX:</p>
<pre>
> time python threadxmd5.py 

real	0m5.154s
user	0m8.989s
sys	0m0.212s
</pre>

Again, whilst the user time is slightly more for threadingx, the real time is nearly half.

<a name='faq'><h2>FAQ</h2></a>

<h3>How does ThreadingX compare with Stackless Python?</h3>

<p>Stackless Python uses 'green' threads which are multitasked within a single operating system thread.
<ul>
<li>This means that stackless python doesn't take advantage of multiple processor cores when they are available</li>
<li>Ultimately, the python Global Interpreter Lock ('GIL') will make it difficult to modify Stackless Python to run across multiple cores effectively</li>
</ul>

<h3>How does ThreadingX compare with Erlang?</h3>

<ul>
<li>Erlang contains OTP, a full-blown infrastructure to manage code replacement and deployment<li>
<li>ThreadingX runs in standard Python, which means things like unicode strings are easy to handle.</li>
<li>ThreadingX doesn't need any knowledge or use of functional programming ('FP') concepts
</ul>

<a name='tutorial'><h2>Tutorial</h2></a>

<p>The tutorial is in two parts:</p>
<ul>
<li>Tutorial part 1: installation, spawn a process, and communicate with it</li>
<li>Tutorial part 2: use the registry process to register and look up process names</li>
</ul>

<h2>Tutorial, part 1: installation, spawn a process, and communicate with it</h2>

<h3>Installation</h3>

<ul>
<li>Download from <a href="http://github.com/hughperkins/python-threadingx/archives/master">python-threadingx</a></li>
<li>Uncompress using tar or unzip</li>
<li>Run 'sudo python setup.py install'</li>
</ul>

<h3>Initializing threadingx</h3>

Create a file called 'main.py', and type in the following:

<pre>
import sys
from threadingxlib import *

class MainService(object):
   def oninit(self, threadx ):
      self.threadx = threadx

      print "Press 'enter' to exit."
      sys.stdin.readline()

      self.threadx.shutdownnow()

threadingx.ThreadingX(MainService())
</pre>

<p>Creating an instance of the ThreadingX class will initialize the threadingx environment, and open a listening port on an available port on your machine.  We pass in an instance of MainService, and threadinx will automatically run the oninit method for us.</p>

<p>In the oninit method, we wait for the user to press 'enter', then we call threadx.shutdownnow(), which will cause threadingx to close all threads and exit.

<p>Run the program, then press enter to exit.</p>

<p>If you are on linux, before pressing enter, you can do 'lsof -i -n -P' to see the port opened by the python process.  On Windows you can use <a href="http://technet.microsoft.com/en-us/sysinternals/bb897437.aspx">tcpview</a></p>

<h3>Spawn a child process</h3>

<p>Let's create a child process.  First we need to create a module for the child process.  Let's create a new text file called 'child.py', in the same directory as 'main.py'.  Type the followinig into child.py:</p>

<pre>
import sys
from threadingxlib import *

class ChildService(object):
   pass

threadx = threadingx.ThreadingX(ChildService())
</pre>

<p>This is a simple child module that will simply run, and wait for the main.py process to tell it to shut-down.</p>

<p>In the main.py, replace the MainService class with:</p>

<pre>
class MainService(object):
   def oninit(self, threadx ):
      self.threadx = threadx

      child = self.threadx.spawn('child')

      print "Press 'enter' to exit."
      sys.stdin.readline()

      self.threadx.shutdownnow()
</pre>

<p>threadx.spawn will launch the child.py module as a new process.  child contains a reference to the child process, termed a 'proxy'.</p>

<p>If you want, you can verify that there are two processes running:</p>
<ul>
<li>Run 'python main.py', and leave running</li>
<li>Use 'ps -ef' in linux, or 'taskmgr.exe' in Windows to see that there are two processes running: 'python main.py' and 'python child.py'.</li>
<li>Back in the terminal, press enter to shut down the main process.</li>
<li>Use ps -ef or taskmgr, and check that the child process has shut down too.</li>
</ul>

<h3>Communicate with a child process</h3>

<p>Let's make a method in the child process, and show how easy it is to call from main.</p>

<p>In main.py, underneath 'child = threadx.spawn('child') add the following line:

<pre>
      child.sendMessage('hello from main')
</pre>

<p>That's it!  That's all we have to do do call a function in the child process!  The child object represents the child process, and we can call methods on it directly.  Technically, the child object is a 'proxy'.</p>

<p>We need to create the sendMessage method in the child.  In child.py, replace the ChildService class with:</p>

<pre>
class ChildService(object):
   def sendMessage( self, sender, message ):
      print "Child received message: " + message
</pre>

<p>Now the child is ready to receive 'sendMessage' function calls from the main process!</p>

<p>We simply print a message to the console, so that we can see that the client received the message ok</p>

<p>Run 'python main.py', and you should see the message 'Child received message: hello from main' appear on the console.</p>
<p>Press enter to shut down the processes</p>

<h3>Send a reply to the main process</h3>

<p>We'd like a way to get the child to communicate results back to the main process.  We can do this using the same function-call semantics we just saw, just in the other direction.</p>

<p>For convenience, in the method on the client, an additional parameter 'sender' is always passed in.  This represents the calling process.  We can simply call method directly on this sender object.</p>

<p>In the main.py, replace the MainService class with:</p>

<pre>
class MainService(object):
   def oninit(self, threadx ):
      self.threadx = threadx
      child = self.threadx.spawn('child')

   def finished( self, sender ):
      print 'Finished'
      self.threadx.shutdownnow()
</pre>

<p>We've added a 'finished' method for the child to call, which calls self.threadx.shutdownnow() for us, which requests threadingx to shut down cleanly.  We've removed the lines from oninit that waited for a user to press a key.</p>

<p>We're left with two methods:</p>
<ul>
<li>oninit spawns the child process</li>
<li>finished prints 'finished' then requests threadingx to shut down cleanly</li>
</ul>

<p>Let's get the child to call the finished method when it receives a message from the main process.  In child.py, at the end of the sendMessage method, add the line:

<pre>
      sender.finished()
</pre>

<p>Easy, right?  The sender object is a proxy object that represents the sender process, so we can simply call methods directly on it like this.</p>

<p>Run 'python main.py, and the child process should state that it received a message, and then the main process should say that it is finished, and then they should both shut down.</p>

<h2>Tutorial, part 2: using the registry process to register and lookup process names</h2>

<p>In part 1 we looked at spawning a child process and communicating it.  What do we do if there are lots of child processes and they want to communicate with each other?</p>

<p>One possibility is to use the 'registry' process, which lets a process register a name and a process object.</p>

&lt; To be written &gt;

<p>In the meantime, you can look at the <a href="http://github.com/hughperkins/python-threadingx/tree/master/examples/pingpong/">'pingpong'</a> example in the 'examples' directory for an example of using the registry process.</p>


<a name='technicaldetails'><h2>Technical Details</h2></a>

<p>Each process is a full-blown Python process.  This eliminates issues with the global interpreter lock.  Communications between processes are over TCP/IP sockets.  We could look at short-cutting the sockets in the future.</p>

<p>Child processes are represented by a proxy class, of class ThreadingX.Proxy.  We override the __getattr__ method, so that we can redirect incoming method calls to the child process.</p>

<p>Call marshalling uses standard python pickle.</p>

<p>proxy objects passed as parameters are marshalled as the port number of the process, and then re-wrapped as a proxy object on the other end.</p>

<p>if the name of a called function is not found in the list of methods registered by the child, threadx holds the call in an internal queue until that method is made available</p>
<ul>
<li>This is somewhat analogous to the matching behavior exhibited by Erlang</li>
</ul>

<p>A new registry process is created each time a process runs which is not a child process.</p>
<ul>
<li>It can be accessed by the method 'getregistry()' on the threadingx object</li>
<li>A process can be registered by calling 'register('somename', childproxyobject )'</li>
<li>A process proxy object can be obtained by calling 'lookup('somename')' on the registry object.</li>
<ul>
<li>The lookup call is synchronous.  In addition, the registry server waits for the name requested to be available, before responding.</li>
</ul>
</ul>


<h2>About</h2>

ThreadingX was written and is maintained by Hugh Perkins.  You can contact me on gmail, as the user 'hughperkins'.

</div>
</div>
</body>
</html>


